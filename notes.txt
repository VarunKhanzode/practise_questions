
asyncio-
Use Case: 
    I/O-bound tasks where you spend time waiting for external resources (e.g., file I/O, network requests, database queries).

    "asyncio is used for writing asynchronous code in Python. It allows a single thread to handle many tasks by switching between 
    them when one task is waiting—like waiting for network or disk operations. It’s ideal for I/O-bound operations where you don't 
    need to use CPU heavily but have to wait a lot, like API calls or reading files."

Example:

    "If I'm making 10 API calls, instead of waiting for one to finish before starting the next, I can use asyncio to start all at once 
    and process responses as they come, saving time."


multithreading-
Use Case: 
    I/O-bound tasks that need low-latency or interaction with libraries that don't support asyncio.

How it works:
    Multiple threads share the same memory space. 
    The Global Interpreter Lock (GIL) in Python allows only one thread to execute Python bytecode at a time, 
    so this isn't effective for CPU-bound tasks.

    "Multithreading uses multiple threads within a single process. It's good for I/O-bound tasks like reading files or making 
    HTTP requests because while one thread waits, another can continue. But in Python, due to the Global Interpreter Lock (GIL), 
    threads don’t run Python code in parallel, so it's not ideal for CPU-bound tasks."

Example:

    "If I have to download multiple images from the internet, I can use multithreading so while one thread waits for a response,
     others continue downloading."

multiprocessing-
Use Case: 
    CPU-bound tasks that require parallel execution across multiple CPU cores.

How it works: 
    Spawns separate processes, each with its own memory space. This bypasses the GIL, making it suitable for CPU-heavy tasks.

    "Multiprocessing creates separate processes, each with its own Python interpreter and memory space. It's best for CPU-bound tasks
     like data processing or calculations because it bypasses the GIL and runs truly in parallel."

Example:

    "If I have to perform a heavy computation like processing millions of records or doing image transformations, 
    I’ll use multiprocessing to split the work across multiple CPU cores."


# Check status of changes
git status

# Stage all changed, new, and deleted files
git add .

# Commit the staged changes with a message
git commit -m "Your commit message here"

# Push to the main branch
git push origin main

# GIL
What is it? - A lock that allows only one thread to run Python code at a time
Why exists? - To protect memory (reference counting) from thread issues
When is it okay? - I/O-bound work (network, file, DB)
When is it bad? - CPU-bound tasks (math, loops)
Alternatives - multiprocessing, NumPy, C extensions


Gil is a mechanism in python which ensures that only one thread can execute python bytecode at a time. It exists to simplify memory management particularly python's reference counting system.
This means that multi threading does not provide true parallelism for CPU bound tasks. Only one thread runs at a time so multi threaded performance gains are limited for heavy computations.

"What is Python’s reference counting system?"
> Python uses reference counting as one of its memory management techniques.
Every object in Python has an internal counter that keeps track of how many references (or variables) are currently pointing to that object.

When a new reference is made, the count increases. When a reference is deleted or goes out of scope, the count decreases.

When the reference count drops to zero, it means the object is no longer being used, and Python automatically frees the memory (i.e., garbage collects the object).

Why is this important for the GIL?

> Because reference counting isn’t thread-safe by default.
If two threads try to update the reference count at the same time, it could lead to memory errors or crashes.

That’s one of the main reasons Python’s GIL exists — it ensures only one thread can modify reference counts at a time.